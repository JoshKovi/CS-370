{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5828575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n",
      "170508288/170498071 [==============================] - 3s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 20s 56ms/step - loss: 1.6961 - accuracy: 0.4022 - val_loss: 1.3666 - val_accuracy: 0.5092\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 1.3442 - accuracy: 0.5242 - val_loss: 1.2236 - val_accuracy: 0.5716\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 18s 56ms/step - loss: 1.2204 - accuracy: 0.5704 - val_loss: 1.1990 - val_accuracy: 0.5746\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 1.1349 - accuracy: 0.6012 - val_loss: 1.1158 - val_accuracy: 0.6089\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 1.0648 - accuracy: 0.6281 - val_loss: 1.0532 - val_accuracy: 0.6322\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 1.0042 - accuracy: 0.6485 - val_loss: 1.0461 - val_accuracy: 0.6391\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.9524 - accuracy: 0.6642 - val_loss: 1.2228 - val_accuracy: 0.5850\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.9077 - accuracy: 0.6836 - val_loss: 1.0371 - val_accuracy: 0.6472\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.8692 - accuracy: 0.6969 - val_loss: 1.1049 - val_accuracy: 0.6263\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.8323 - accuracy: 0.7112 - val_loss: 0.9947 - val_accuracy: 0.6608\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7949 - accuracy: 0.7229 - val_loss: 1.0470 - val_accuracy: 0.6535\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7605 - accuracy: 0.7363 - val_loss: 0.9998 - val_accuracy: 0.6687\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.7357 - accuracy: 0.7447 - val_loss: 1.0132 - val_accuracy: 0.6695\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.6973 - accuracy: 0.7591 - val_loss: 0.9811 - val_accuracy: 0.6846\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6750 - accuracy: 0.7643 - val_loss: 1.0319 - val_accuracy: 0.6627\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6547 - accuracy: 0.7722 - val_loss: 1.0469 - val_accuracy: 0.6580\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6346 - accuracy: 0.7829 - val_loss: 1.0284 - val_accuracy: 0.6798\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.6112 - accuracy: 0.7898 - val_loss: 1.0181 - val_accuracy: 0.6789\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.5888 - accuracy: 0.7978 - val_loss: 1.0600 - val_accuracy: 0.6571\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.5749 - accuracy: 0.8011 - val_loss: 1.1255 - val_accuracy: 0.6727\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 1.1132 - accuracy: 0.6705\n",
      "Test score: 1.1131540536880493\n",
      "Test accuracy: 0.6704999804496765\n"
     ]
    }
   ],
   "source": [
    "#Basic Convolutional Net\n",
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "\n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 20 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) \n",
    "model.summary()\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=OPTIM, metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, \n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "          verbose=VERBOSE) \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE) \n",
    "\n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d663455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 32)          18464     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 2, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 1.9676 - accuracy: 0.2718 - val_loss: 1.7316 - val_accuracy: 0.3595\n",
      "Epoch 2/40\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.7008 - accuracy: 0.3683 - val_loss: 1.5414 - val_accuracy: 0.4343\n",
      "Epoch 3/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.5552 - accuracy: 0.4295 - val_loss: 1.4402 - val_accuracy: 0.4735\n",
      "Epoch 4/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.4592 - accuracy: 0.4670 - val_loss: 1.3223 - val_accuracy: 0.5175\n",
      "Epoch 5/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.3899 - accuracy: 0.4961 - val_loss: 1.3757 - val_accuracy: 0.5089\n",
      "Epoch 6/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.3341 - accuracy: 0.5195 - val_loss: 1.2666 - val_accuracy: 0.5509\n",
      "Epoch 7/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.2838 - accuracy: 0.5391 - val_loss: 1.1682 - val_accuracy: 0.5773\n",
      "Epoch 8/40\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.2433 - accuracy: 0.5520 - val_loss: 1.1329 - val_accuracy: 0.5934\n",
      "Epoch 9/40\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.2072 - accuracy: 0.5677 - val_loss: 1.1578 - val_accuracy: 0.5812\n",
      "Epoch 10/40\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.1723 - accuracy: 0.5810 - val_loss: 1.0479 - val_accuracy: 0.6269\n",
      "Epoch 11/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.1439 - accuracy: 0.5936 - val_loss: 1.0414 - val_accuracy: 0.6287\n",
      "Epoch 12/40\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 1.1226 - accuracy: 0.5986 - val_loss: 1.0814 - val_accuracy: 0.6174\n",
      "Epoch 13/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 1.1106 - accuracy: 0.6098 - val_loss: 1.0638 - val_accuracy: 0.6300\n",
      "Epoch 14/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 1.0867 - accuracy: 0.6138 - val_loss: 1.0096 - val_accuracy: 0.6406\n",
      "Epoch 15/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 1.0676 - accuracy: 0.6213 - val_loss: 0.9493 - val_accuracy: 0.6631\n",
      "Epoch 16/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 1.0493 - accuracy: 0.6277 - val_loss: 0.9613 - val_accuracy: 0.6640\n",
      "Epoch 17/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 1.0334 - accuracy: 0.6369 - val_loss: 1.0188 - val_accuracy: 0.6388\n",
      "Epoch 18/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 1.0246 - accuracy: 0.6365 - val_loss: 0.9326 - val_accuracy: 0.6781\n",
      "Epoch 19/40\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1.0092 - accuracy: 0.6424 - val_loss: 0.9485 - val_accuracy: 0.6646\n",
      "Epoch 20/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9961 - accuracy: 0.6498 - val_loss: 0.9242 - val_accuracy: 0.6684\n",
      "Epoch 21/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9856 - accuracy: 0.6528 - val_loss: 0.9250 - val_accuracy: 0.6782\n",
      "Epoch 22/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9698 - accuracy: 0.6550 - val_loss: 0.9959 - val_accuracy: 0.6555\n",
      "Epoch 23/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9674 - accuracy: 0.6599 - val_loss: 0.9083 - val_accuracy: 0.6838\n",
      "Epoch 24/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9557 - accuracy: 0.6659 - val_loss: 0.9604 - val_accuracy: 0.6607\n",
      "Epoch 25/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9470 - accuracy: 0.6664 - val_loss: 0.9296 - val_accuracy: 0.6689\n",
      "Epoch 26/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9358 - accuracy: 0.6731 - val_loss: 0.9328 - val_accuracy: 0.6738\n",
      "Epoch 27/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9292 - accuracy: 0.6745 - val_loss: 0.9378 - val_accuracy: 0.6741\n",
      "Epoch 28/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9198 - accuracy: 0.6760 - val_loss: 0.9458 - val_accuracy: 0.6665\n",
      "Epoch 29/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9249 - accuracy: 0.6781 - val_loss: 0.9104 - val_accuracy: 0.6786\n",
      "Epoch 30/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.9079 - accuracy: 0.6813 - val_loss: 0.8678 - val_accuracy: 0.6979\n",
      "Epoch 31/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8985 - accuracy: 0.6835 - val_loss: 0.8806 - val_accuracy: 0.6953\n",
      "Epoch 32/40\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.8943 - accuracy: 0.6845 - val_loss: 0.9159 - val_accuracy: 0.6837\n",
      "Epoch 33/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8952 - accuracy: 0.6869 - val_loss: 0.8878 - val_accuracy: 0.6877\n",
      "Epoch 34/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8860 - accuracy: 0.6892 - val_loss: 1.0352 - val_accuracy: 0.6435\n",
      "Epoch 35/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8813 - accuracy: 0.6945 - val_loss: 0.8562 - val_accuracy: 0.7065\n",
      "Epoch 36/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8761 - accuracy: 0.6916 - val_loss: 0.8792 - val_accuracy: 0.6911\n",
      "Epoch 37/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8780 - accuracy: 0.6910 - val_loss: 0.9989 - val_accuracy: 0.6562\n",
      "Epoch 38/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.8760 - accuracy: 0.6945 - val_loss: 0.8439 - val_accuracy: 0.7073\n",
      "Epoch 39/40\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.8633 - accuracy: 0.6941 - val_loss: 0.8456 - val_accuracy: 0.7108\n",
      "Epoch 40/40\n",
      "313/313 [==============================] - 34s 107ms/step - loss: 0.8648 - accuracy: 0.6959 - val_loss: 0.8800 - val_accuracy: 0.6957\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.8903 - accuracy: 0.6967\n",
      "Test score: 0.8903350830078125\n",
      "Test accuracy: 0.6966999769210815\n"
     ]
    }
   ],
   "source": [
    "#Deep Convolutional net\n",
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "\n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 40 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32, 3,3))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) \n",
    "model.summary()\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=OPTIM, metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, \n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "          verbose=VERBOSE) \n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE) \n",
    "\n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21af5625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting\n",
      "50000\n",
      "New Training length:  60240 , Time Elapsed in Seconds for Augmentation:  18.406030893325806\n",
      "X_train shape: (60240, 32, 32, 3)\n",
      "60240 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 5, 5, 32)          18464     \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 2, 2, 32)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "377/377 [==============================] - 44s 108ms/step - loss: 1.9561 - accuracy: 0.2695 - val_loss: 1.7451 - val_accuracy: 0.3632\n",
      "Epoch 2/50\n",
      "377/377 [==============================] - 41s 108ms/step - loss: 1.6482 - accuracy: 0.3895 - val_loss: 1.6565 - val_accuracy: 0.4011\n",
      "Epoch 3/50\n",
      "377/377 [==============================] - 41s 108ms/step - loss: 1.5036 - accuracy: 0.4492 - val_loss: 1.6978 - val_accuracy: 0.3978\n",
      "Epoch 4/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.4161 - accuracy: 0.4842 - val_loss: 1.5712 - val_accuracy: 0.4388\n",
      "Epoch 5/50\n",
      "377/377 [==============================] - 41s 108ms/step - loss: 1.3415 - accuracy: 0.5145 - val_loss: 1.5951 - val_accuracy: 0.4393\n",
      "Epoch 6/50\n",
      "377/377 [==============================] - 41s 108ms/step - loss: 1.2869 - accuracy: 0.5394 - val_loss: 1.4550 - val_accuracy: 0.4916\n",
      "Epoch 7/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.2377 - accuracy: 0.5557 - val_loss: 1.4951 - val_accuracy: 0.4899\n",
      "Epoch 8/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.1951 - accuracy: 0.5725 - val_loss: 1.7184 - val_accuracy: 0.4207\n",
      "Epoch 9/50\n",
      "377/377 [==============================] - 42s 111ms/step - loss: 1.1590 - accuracy: 0.5845 - val_loss: 1.5405 - val_accuracy: 0.4818\n",
      "Epoch 10/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.1299 - accuracy: 0.5956 - val_loss: 1.4677 - val_accuracy: 0.5027\n",
      "Epoch 11/50\n",
      "377/377 [==============================] - 41s 108ms/step - loss: 1.0992 - accuracy: 0.6092 - val_loss: 1.4986 - val_accuracy: 0.4935\n",
      "Epoch 12/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.0739 - accuracy: 0.6168 - val_loss: 1.6704 - val_accuracy: 0.4516\n",
      "Epoch 13/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.0472 - accuracy: 0.6279 - val_loss: 1.7710 - val_accuracy: 0.4359\n",
      "Epoch 14/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.0268 - accuracy: 0.6366 - val_loss: 1.4865 - val_accuracy: 0.5047\n",
      "Epoch 15/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 1.0126 - accuracy: 0.6416 - val_loss: 1.5030 - val_accuracy: 0.4910\n",
      "Epoch 16/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9979 - accuracy: 0.6469 - val_loss: 1.5837 - val_accuracy: 0.4802\n",
      "Epoch 17/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9839 - accuracy: 0.6491 - val_loss: 1.4872 - val_accuracy: 0.5140\n",
      "Epoch 18/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9664 - accuracy: 0.6607 - val_loss: 1.3924 - val_accuracy: 0.5273\n",
      "Epoch 19/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9606 - accuracy: 0.6620 - val_loss: 1.4475 - val_accuracy: 0.5203\n",
      "Epoch 20/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9524 - accuracy: 0.6662 - val_loss: 1.8512 - val_accuracy: 0.4524\n",
      "Epoch 21/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9338 - accuracy: 0.6690 - val_loss: 1.6109 - val_accuracy: 0.4885\n",
      "Epoch 22/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.9277 - accuracy: 0.6730 - val_loss: 1.4861 - val_accuracy: 0.5237\n",
      "Epoch 23/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.9201 - accuracy: 0.6766 - val_loss: 1.6483 - val_accuracy: 0.4869\n",
      "Epoch 24/50\n",
      "377/377 [==============================] - 42s 113ms/step - loss: 0.9127 - accuracy: 0.6814 - val_loss: 1.5283 - val_accuracy: 0.4929\n",
      "Epoch 25/50\n",
      "377/377 [==============================] - 42s 112ms/step - loss: 0.9090 - accuracy: 0.6797 - val_loss: 1.7734 - val_accuracy: 0.4702\n",
      "Epoch 26/50\n",
      "377/377 [==============================] - 42s 111ms/step - loss: 0.9059 - accuracy: 0.6839 - val_loss: 1.3768 - val_accuracy: 0.5419\n",
      "Epoch 27/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.8957 - accuracy: 0.6861 - val_loss: 1.6140 - val_accuracy: 0.5006\n",
      "Epoch 28/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.8879 - accuracy: 0.6896 - val_loss: 1.3498 - val_accuracy: 0.5462\n",
      "Epoch 29/50\n",
      "377/377 [==============================] - 43s 113ms/step - loss: 0.8886 - accuracy: 0.6881 - val_loss: 1.2876 - val_accuracy: 0.5637\n",
      "Epoch 30/50\n",
      "377/377 [==============================] - 43s 113ms/step - loss: 0.8725 - accuracy: 0.6935 - val_loss: 1.3463 - val_accuracy: 0.5468\n",
      "Epoch 31/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.8772 - accuracy: 0.6929 - val_loss: 1.5415 - val_accuracy: 0.5113\n",
      "Epoch 32/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8657 - accuracy: 0.6954 - val_loss: 1.5624 - val_accuracy: 0.5033\n",
      "Epoch 33/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.8663 - accuracy: 0.6951 - val_loss: 1.6911 - val_accuracy: 0.5007\n",
      "Epoch 34/50\n",
      "377/377 [==============================] - 42s 111ms/step - loss: 0.8640 - accuracy: 0.6985 - val_loss: 1.4288 - val_accuracy: 0.5378\n",
      "Epoch 35/50\n",
      "377/377 [==============================] - 42s 112ms/step - loss: 0.8540 - accuracy: 0.6988 - val_loss: 1.3856 - val_accuracy: 0.5512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "377/377 [==============================] - 42s 112ms/step - loss: 0.8558 - accuracy: 0.7023 - val_loss: 1.5919 - val_accuracy: 0.5129\n",
      "Epoch 37/50\n",
      "377/377 [==============================] - 42s 111ms/step - loss: 0.8530 - accuracy: 0.7005 - val_loss: 1.4182 - val_accuracy: 0.5388\n",
      "Epoch 38/50\n",
      "377/377 [==============================] - 42s 110ms/step - loss: 0.8552 - accuracy: 0.7003 - val_loss: 1.4217 - val_accuracy: 0.5378\n",
      "Epoch 39/50\n",
      "377/377 [==============================] - 43s 113ms/step - loss: 0.8467 - accuracy: 0.7034 - val_loss: 1.5179 - val_accuracy: 0.5155\n",
      "Epoch 40/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8446 - accuracy: 0.7040 - val_loss: 1.3577 - val_accuracy: 0.5539\n",
      "Epoch 41/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8522 - accuracy: 0.7042 - val_loss: 1.5241 - val_accuracy: 0.5171\n",
      "Epoch 42/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8427 - accuracy: 0.7064 - val_loss: 1.7170 - val_accuracy: 0.4972\n",
      "Epoch 43/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8416 - accuracy: 0.7070 - val_loss: 1.3404 - val_accuracy: 0.5490\n",
      "Epoch 44/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8351 - accuracy: 0.7099 - val_loss: 1.5720 - val_accuracy: 0.5154\n",
      "Epoch 45/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.8319 - accuracy: 0.7085 - val_loss: 1.6354 - val_accuracy: 0.5110\n",
      "Epoch 46/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.8339 - accuracy: 0.7108 - val_loss: 1.5945 - val_accuracy: 0.5170\n",
      "Epoch 47/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8394 - accuracy: 0.7082 - val_loss: 1.4885 - val_accuracy: 0.5229\n",
      "Epoch 48/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.8219 - accuracy: 0.7132 - val_loss: 1.5356 - val_accuracy: 0.5391\n",
      "Epoch 49/50\n",
      "377/377 [==============================] - 41s 109ms/step - loss: 0.8359 - accuracy: 0.7091 - val_loss: 1.7323 - val_accuracy: 0.5040\n",
      "Epoch 50/50\n",
      "377/377 [==============================] - 41s 110ms/step - loss: 0.8278 - accuracy: 0.7132 - val_loss: 1.5390 - val_accuracy: 0.5296\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.8227 - accuracy: 0.7195\n",
      "Test score: 0.8226760029792786\n",
      "Test accuracy: 0.7195000052452087\n"
     ]
    }
   ],
   "source": [
    "#Deep data Aug Convolutional net\n",
    "import keras\n",
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "\n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 50 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "\n",
    "\n",
    "#Augmenting\n",
    "print (\"Augmenting\")\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 40, width_shift_range=0.2,\n",
    "                            height_shift_range = 2.0, zoom_range = 0.2,\n",
    "                            horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "\n",
    "initial_Size = X_train.shape[0]\n",
    "\n",
    "print(initial_Size)\n",
    "start = time.time()\n",
    "\n",
    "for i in range(initial_Size):\n",
    "    num_aug = 0\n",
    "    for x_aug, y_aug in datagen.flow(X_train, y_train, batch_size = BATCH_SIZE):\n",
    "        X_train = np.append(X_train, x_aug, axis=0)\n",
    "        y_train = np.append(y_train, y_aug, axis=0)\n",
    "        num_aug+=1\n",
    "        if(num_aug >= NUM_TO_AUGMENT):\n",
    "            break\n",
    "    if(len(X_train) >= 60000):\n",
    "        break #Python runs into a available memory error on my PC past 60k images\n",
    "            \n",
    "end = time.time()\n",
    "print(\"New Training length: \" , len(X_train) ,\", Time Elapsed in Seconds for Augmentation: \" , (end-start))\n",
    "\n",
    "\n",
    "#fit datagen\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape) \n",
    "print(len(X_train), 'train samples') \n",
    "print(len(X_test), 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32, 3,3))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) \n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=OPTIM, metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, \n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "          verbose=VERBOSE) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE) \n",
    "\n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fc1de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_116 (Conv2D)         (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_167 (Activation)  (None, 32, 32, 32)       0         \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_168 (Activation)  (None, 32, 32, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_169 (Activation)  (None, 16, 16, 64)       0         \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 5, 5, 32)          18464     \n",
      "                                                                 \n",
      " activation_170 (Activation)  (None, 5, 5, 32)         0         \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 2, 2, 32)          0         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " activation_171 (Activation)  (None, 512)              0         \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_172 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 45s 113ms/step - loss: 2.0162 - accuracy: 0.2479\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.8063 - accuracy: 0.3331\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 45s 115ms/step - loss: 1.7075 - accuracy: 0.3749\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 45s 115ms/step - loss: 1.6486 - accuracy: 0.3921\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 1.5919 - accuracy: 0.4177\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 45s 116ms/step - loss: 1.5515 - accuracy: 0.4372\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 1.5185 - accuracy: 0.4500\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 1.4930 - accuracy: 0.4600\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 47s 119ms/step - loss: 1.4648 - accuracy: 0.4725\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 1.4470 - accuracy: 0.4795\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 1.4186 - accuracy: 0.4901\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.4064 - accuracy: 0.4966\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.3935 - accuracy: 0.5017\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.3816 - accuracy: 0.5051\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.3674 - accuracy: 0.5112\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 44s 114ms/step - loss: 1.3601 - accuracy: 0.5128\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.3477 - accuracy: 0.5205\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.3328 - accuracy: 0.5236\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.3249 - accuracy: 0.5272\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.3183 - accuracy: 0.5326\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 62s 158ms/step - loss: 1.3143 - accuracy: 0.5336\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 47s 119ms/step - loss: 1.3133 - accuracy: 0.5382\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 47s 120ms/step - loss: 1.3047 - accuracy: 0.5353\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 1.2976 - accuracy: 0.5407\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 1.2984 - accuracy: 0.5395\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 47s 120ms/step - loss: 1.2935 - accuracy: 0.5419\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 47s 120ms/step - loss: 1.2867 - accuracy: 0.5465\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 47s 120ms/step - loss: 1.2824 - accuracy: 0.5446\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.2824 - accuracy: 0.5463\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.2721 - accuracy: 0.5512\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.2739 - accuracy: 0.5487\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 43s 111ms/step - loss: 1.2717 - accuracy: 0.5521\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.2629 - accuracy: 0.5544\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.2656 - accuracy: 0.5540\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 45s 116ms/step - loss: 1.2616 - accuracy: 0.5571\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 1.2600 - accuracy: 0.5562\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.2536 - accuracy: 0.5590\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 46s 116ms/step - loss: 1.2584 - accuracy: 0.5601\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 45s 115ms/step - loss: 1.2563 - accuracy: 0.5576\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 1.2539 - accuracy: 0.5581\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 44s 114ms/step - loss: 1.2483 - accuracy: 0.5616\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.2418 - accuracy: 0.5639\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.2475 - accuracy: 0.5627\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 1.2529 - accuracy: 0.5611\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 45s 115ms/step - loss: 1.2382 - accuracy: 0.5645\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 45s 116ms/step - loss: 1.2419 - accuracy: 0.5648\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 47s 119ms/step - loss: 1.2391 - accuracy: 0.5677\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 1.2409 - accuracy: 0.5666\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 1.2426 - accuracy: 0.5659\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 46s 118ms/step - loss: 1.2388 - accuracy: 0.5660\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 1.0820 - accuracy: 0.6200\n",
      "Test score: 1.082026720046997\n",
      "Test accuracy: 0.6200000047683716\n"
     ]
    }
   ],
   "source": [
    "#Deep data Aug Convolutional net on the spot augmentation\n",
    "import keras\n",
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "\n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 50 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "\n",
    "\n",
    "#Augmenting\n",
    "print (\"Augmenting\")\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 40, width_shift_range=0.2,\n",
    "                            height_shift_range = 2.0, zoom_range = 0.2,\n",
    "                            horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "\n",
    "\n",
    "#fit datagen\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape) \n",
    "print(len(X_train), 'train samples') \n",
    "print(len(X_test), 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3), padding = 'same'))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(32, 3,3))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) \n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=OPTIM, metrics=['accuracy']) \n",
    "model.fit(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE) , batch_size=BATCH_SIZE, \n",
    "          epochs=NB_EPOCH, #validation_split=VALIDATION_SPLIT, \n",
    "          verbose=VERBOSE) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE) \n",
    "\n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003e5c3",
   "metadata": {},
   "source": [
    "An algorithm like this could easily (maybe not so easily) be trained to recognize faces and other factors. While this may take a large amount of data, like the scrapping of entire social media sites it is possible. The ethical concern is that people will be identified unwillingly or have their privacy invaded by having their picture taken and then being identified doing something or being somewhere they may not want associated with their name. In my personal opinion, the cat is already out of the bag so to speak. While not everyone realized it at the time, or even realizes it yet, whenever you post a picture online there is a high probability that someone, somewhere will scrap that image and put it in a database. It was revealed years ago (with Edward Snowden) that the NSA and other agencies were already doing this type of thing (Greenwald et al., 2013), long before corporations were. While this may feel like an invasion of privacy (and may be one in terms of government) this is effectively just a new public domain. You are generally not entitled to privacy when in public, in effect the internet has become another public space and as such it is no more private than walking around your grocery store or city. The only major difference is that now individuals have data gathering capabilities that exceed what the largest governments could have done only 20 years ago.  \n",
    "    A major concern is the alleged \"right to be forgotten\", which unfortunately is generally not a right at all(Everything You Need to Know about the Right to Be Forgotten - GDPR.eu, 2018). While I wish that all companies were required to delete your information when you ask, I think that even that would not guarantee you any degree of aninimity. The problem is that once you post something online, it is nearly impossible to get rid of it. Ask any celebrity that has gotten into trouble over a deleted tweet from 10+ years ago. Everything on the internet is recorded, everything is scraped. The right to be forgotten is only effective when you know who has, or may have your data, but as the reading from this week, it is not likely that you do outside a handful of agencies. To top it off, most of those agencies require you to sign their terms and conditions that allow them to sell your data as they please in exchange for using their service. \n",
    "    While I am no expert, I am probably barely even a novice in AI, I know that with time and effort I could find a way to scrape enough pictures off the internet to feed this algorithm above or one like it and generate some amount of accuracy when identifying pictures of people. If I were to do this, It would be one of thousands if not more algorithms designed to do just that. The problem is not that it is ethically or morally wrong to do this, because it is already being done on such a scale that no individual, or government for that matter could even put a dent in it. The real issue is that there are still people using social media that do not understand this can be done, and have no idea how to reduce its effect on them. I think the ethical concern now is in not educating the public about this, and how they can protect themselves (to a degree) from these types of algorithms. Personally, I do not even know that education on the subject matters when most major government agencies in every major government is using this technology. They attempted to impliement facial recognition software at my work for a controlled access area at one point (though the pushback from workers was so strong they had to back down). The fact is, while you could potentially use these algorithms for some nefarious purpose, there is probably already someone doing it for just that, while having none of the moral or ethical reservations you or I may have.\n",
    "    \n",
    "Everything you need to know about the Right to be forgotten - GDPR.eu. (2018, November 5). GDPR.eu. https://gdpr.eu/right-to-be-forgotten/\n",
    "\n",
    "\n",
    "Greenwald, G., MacAskill, E., & Poitras, L. (2013, June 11). Edward Snowden: the whistleblower behind the NSA surveillance revelations. The Guardian; The Guardian. https://www.theguardian.com/world/2013/jun/09/edward-snowden-nsa-whistleblower-surveillance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
